# **RL-Tennis-Simulator: Reinforcement Learning for Tennis Returns**  

## **ğŸ¾ Overview**  
RL-Tennis-Simulator is a **reinforcement learning (RL) environment** designed to train an **AI agent** to return a tennis ball using a paddle. The environment is built using **Gymnasium**, **Pymunk (2D physics),** and **Pygame (rendering)**, with training powered by **Stable-Baselines3 (PPO algorithm).**  

ğŸš€ **Key Features:**  
âœ… **Physics-Based RL Environment** â†’ Simulates realistic ball dynamics using Pymunk  
âœ… **Gymnasium-Compatible** â†’ Custom RL environment follows OpenAI Gym API standards  
âœ… **Trainable RL Agent** â†’ Uses Proximal Policy Optimization (PPO) to learn optimal paddle movements  
âœ… **Interactive Visualization** â†’ Watch the agent in action via Pygame rendering  

---

## **ğŸ› ï¸ Tech Stack**  
âœ… **Python** â€“ Core programming language  
âœ… **Gymnasium** â€“ RL environment interface  
âœ… **Stable-Baselines3 (PPO)** â€“ RL algorithm for training  
âœ… **Pymunk** â€“ 2D physics engine for ball movement  
âœ… **Pygame** â€“ Rendering for interactive visualization  

---

## **ğŸ“ Project Structure**  

```bash
â”œâ”€â”€ rl-tennis-simulator/
â”‚   â”œâ”€â”€ tennis_env.py        # Custom Gymnasium environment with physics simulation
â”‚   â”œâ”€â”€ train_agent.py       # Training script for PPO RL agent
â”‚   â”œâ”€â”€ main.py              # Runs the trained agent in real-time
â”‚   â”œâ”€â”€ requirements.txt     # Python dependencies
â”‚   â”œâ”€â”€ README.md            # Project documentation (this file)
```

---

## **ğŸš€ Setup & Installation**  

### **1ï¸âƒ£ Create & Activate Virtual Environment**  
```bash
python -m venv venv
source venv/bin/activate    # Linux/Mac
venv\Scripts\activate       # Windows
```

### **2ï¸âƒ£ Install Dependencies**  
```bash
pip install -r requirements.txt
```

---

## **ğŸ¤– Training the RL Agent**  

### **1ï¸âƒ£ Run Training Script (Using PPO Algorithm)**  
```bash
python train_agent.py
```
This trains the agent using **10,000 timesteps**. Adjust `total_timesteps` in `train_agent.py` for longer training.  

### **2ï¸âƒ£ Save & Load the Model**  
```python
from stable_baselines3 import PPO

# Save the trained model
model.save("tennis_ppo_model")

# Load the model for inference
model = PPO.load("tennis_ppo_model")
```

---

## **ğŸ¾ Running the Trained Agent**  

Once the agent is trained, watch it play in real-time with **Pygame rendering**:  
```bash
python main.py
```

---

## **ğŸ“Š Environment Details**  

### **State Space (Observations)**  
Each state consists of **6 features**:  
1. **Ball X position** (float)  
2. **Ball Y position** (float)  
3. **Ball X velocity** (float)  
4. **Ball Y velocity** (float)  
5. **Paddle X position** (float)  
6. **Paddle X velocity** (float)  

### **Action Space**  
The RL agent can take **3 discrete actions**:  
- **0** â†’ Move paddle **left**  
- **1** â†’ **Stay** in the same position  
- **2** â†’ Move paddle **right**  

### **Rewards Shaping**  
- **+1 reward** â†’ When the agent successfully returns the ball, with an additional bonus based on how centered the ball is on the paddle and an incremental bonus for consecutive hits.  
- **-0.01 penalty** â†’ Applied every step to encourage faster responses.  
- **-1 penalty** â†’ When the ball falls past the paddle, the episode ends with a reward of -1.0, and the total `episode_hits` is passed in the info dictionary.  

### **Metrics & Logs**
- **episode_hits** â†’ Total number of successful hits in an episode.
- **episode_hits_rate** â†’ Ratio of successful hits to total attempts.
- **episode_duration** â†’ Number of steps taken in an episode.
- **episode_reward** â†’ Total reward accumulated in an episode.

---

## **ğŸ–¼ï¸ Visualizing the Simulation**  
The environment renders a **2D simulation** of the paddle and ball using **Pygame**.  

âœ… **White Paddle** â†’ Agent-controlled  
âœ… **Yellow Ball** â†’ Follows physics-based movement  
âœ… **Black Background** â†’ Simplifies visualization  

---

## **ğŸ”® Next Steps & Improvements**  
ğŸ”¹ **Train with More Advanced RL Algorithms** (e.g., SAC, DDPG)  
ğŸ”¹ **Enhance Reward Function** (Improve paddle precision feedback)  
ğŸ”¹ **Multi-Agent Training** (Opponent AI for rallies)  
ğŸ”¹ **Improve Rendering** (More realistic visuals)  

---

## **ğŸ“Œ Why This Project Matters?**  
RL-Tennis-Simulator **demonstrates reinforcement learning in a physics-based setting**, providing:  
- **Hands-on RL environment development experience**  
- **Practical application of Gymnasium & Stable-Baselines3**  
- **A foundation for AI-based sports simulations**  